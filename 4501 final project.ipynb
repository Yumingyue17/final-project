{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "058392ff-2eae-49ae-85d6-a228fc65d0ee",
   "metadata": {},
   "source": [
    "# 4501 final project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import geopandas as gpd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as pltx\n",
    "from urllib.parse import urljoin\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TLC_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"weather\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\"\n",
    "\n",
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b58c84-7d3e-4a21-ae40-0444edeb6ec4",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b24433-dd3d-4cce-84d6-211285024a57",
   "metadata": {},
   "source": [
    "Define a function download_file(link, save_dir) that efficiently download files ensuring that no duplicate downloads occur if the file already exists in the target directory and Saves the file in chunks of 8192 bytes to avoid memory overload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4988e20-4616-4cc8-800d-83a5e9fa6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local directory to save downloaded files\n",
    "download_dir = \"./nyc_taxi_data\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Function to download a file\n",
    "def download_file(link, save_dir):\n",
    "    file_name = link.split(\"/\")[-1]\n",
    "    file_path = os.path.join(save_dir, file_name)\n",
    "    # Skip download if the file already exists\n",
    "    if not os.path.exists(file_path):  \n",
    "        print(f\"Downloading {file_name}...\")\n",
    "        response = requests.get(link, stream=True)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Saved to {file_path}\")\n",
    "    else:\n",
    "        print(f\"{file_name} already exists. Skipping download.\")\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3cdb74-9a0b-479d-acd9-5f3349ef1dee",
   "metadata": {},
   "source": [
    "* Scraping a webpage for links to Yellow Taxi and HVFHV Parquet data files.\n",
    "* Downloading only the relevant files based on naming patterns and storing them locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d78db7-4e2d-4dc8-9303-3526bf48a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow_tripdata_2024-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-10.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-10.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-11.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-11.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-12.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-12.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-10.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-10.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-11.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-11.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-12.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-12.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-10.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-10.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-11.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-11.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-12.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-12.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-10.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-10.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-11.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-11.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-12.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-12.parquet already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Fetch the webpage content\n",
    "response = requests.get(TLC_URL)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "else:\n",
    "    raise Exception(\"Failed to fetch the TLC page.\")\n",
    "\n",
    "# Regular expressions to match Yellow Taxi and HVFHV links\n",
    "yellow_taxi_regex = re.compile(r\"yellow_tripdata_(202[0-4])-(0[1-9]|1[0-2])\\.parquet\", re.IGNORECASE)\n",
    "hvfhv_regex = re.compile(r\"fhvhv_tripdata_(202[0-4])-(0[1-9]|1[0-2])\\.parquet\", re.IGNORECASE)\n",
    "\n",
    "# Find all links on the page\n",
    "links = soup.find_all('a', href=True)\n",
    "\n",
    "# File path\n",
    "taxi_path = []\n",
    "hvfhv_path = []\n",
    "\n",
    "# Filter and download Yellow Taxi and HVFHV Parquet files\n",
    "taxi_path, hvfhv_path = [], []\n",
    "for link in soup.find_all(\"a\", href=True):\n",
    "    url = urljoin(\"https://www1.nyc.gov\", link[\"href\"].strip())\n",
    "    if yellow_taxi_regex.search(url):\n",
    "        taxi_path.append(download_file(url, download_dir))\n",
    "    elif hvfhv_regex.search(url):\n",
    "        hvfhv_path.append(download_file(url, download_dir))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a9aad-c9a8-4ab0-9fe2-1e327df9123c",
   "metadata": {},
   "source": [
    "* The first function (load_taxi_zones) processes and prepares taxi zone data from a shapefile for geospatial analysis.\n",
    "* The second function (lookup_coords_for_taxi_zone_id) finds the latitude and longitude coordinates of a taxi zone based on its LocationID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(shapefile_path):\n",
    "    taxi_zones = gpd.read_file(shapefile_path)\n",
    "    taxi_zones = taxi_zones.to_crs(4326)  # Reproject to lat/lon (WGS84)\n",
    "    taxi_zones['lon'] = taxi_zones.centroid.x  # Calculate longitude from centroid\n",
    "    taxi_zones['lat'] = taxi_zones.centroid.y  # Calculate latitude from centroid\n",
    "    return taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_coords_for_taxi_zone_id(zone_loc_id, loaded_taxi_zones):\n",
    "    zone = loaded_taxi_zones[loaded_taxi_zones['LocationID'] == zone_loc_id]\n",
    "    if not zone.empty:\n",
    "        return zone.iloc[0]['lat'], zone.iloc[0]['lon']\n",
    "    return None, None  # Return None if the location ID is invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d31728-9c65-47d8-b57e-6c63527d0475",
   "metadata": {},
   "source": [
    "Create a representative sample using Cochran's Sample Size Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(population, margin_of_error=0.05):\n",
    "    z = 1.96  # For 95% confidence\n",
    "    p = 0.5  # Assumed proportion of 50% (worst-case scenario)\n",
    "    q = 1 - p\n",
    "    e = margin_of_error\n",
    "    pop = population.shape[0]\n",
    "    # Cochran's sample size formula\n",
    "    sample_size = (z ** 2 * p * q) / (e ** 2)\n",
    "    # Adjust sample size for finite population\n",
    "    sample_size = sample_size / (1 + (sample_size - 1) / pop)\n",
    "    sampled_df = population.sample(n=math.ceil(sample_size), random_state=42)\n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82a613-9c23-46bc-b97c-451c14b0eb3e",
   "metadata": {},
   "source": [
    "Append latitude and longitude coordinates for pickup and drop-off locations to taxi_data DataFrame by mapping them from a preloaded taxi zones dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c6a78da-9c4a-401f-a3d2-3354bf28bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates_to_taxi_data(taxi_data, loaded_taxi_zones):\n",
    "    taxi_data[['PUlat', 'PUlon']] = taxi_data['PULocationID'].apply(\n",
    "        lambda x: pd.Series(lookup_coords_for_taxi_zone_id(x, loaded_taxi_zones))\n",
    "    )\n",
    "    taxi_data[['DOlat', 'DOlon']] = taxi_data['DOLocationID'].apply(\n",
    "        lambda x: pd.Series(lookup_coords_for_taxi_zone_id(x, loaded_taxi_zones))\n",
    "    )\n",
    "    taxi_data = taxi_data.drop(columns=['PULocationID', 'DOLocationID'])\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca3c1d5-6058-4bfc-9e49-c228c1e85036",
   "metadata": {},
   "source": [
    "1. Load Data: Reads a Parquet file specified by path into a pandas DataFrame using pd.read_parquet().\n",
    "\n",
    "2. Initial Filtering:\n",
    " - Removes trips with zero or negative distances (trip_distance > 0).\n",
    " - Excludes trips where the pickup and drop-off locations are the same (PULocationID != DOLocationID).\n",
    " - Ensures the PULocationID and DOLocationID values are within the valid range of 1–263 .\n",
    "\n",
    "3. Handle Missing Data: Drops rows with missing values in the trip_distance, PULocationID, or DOLocationID columns.\n",
    "\n",
    "4. Sampling: Calculates the required sample size using calculate_sample_size() and selects a random sample from the dataset.\n",
    "\n",
    "5. Add Geographic Coordinates: Enriches the dataset by adding latitude and longitude columns for both pickup and drop-off locations using the add_coordinates_to_taxi_data() function.\n",
    "\n",
    "6. Filter by Geographic Boundaries: Filters trips to ensure pickup and drop-off locations are within specific latitude and longitude ranges.\n",
    "\n",
    "7. Remove Unnecessary Columns: Drops columns that are not relevant for further analysis, such as: RatecodeID, store_and_fwd_flag, payment_type, extra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month(path, loaded_taxi_zones):\n",
    "    a = pd.read_parquet(path)\n",
    "    a = a[(a['trip_distance'] > 0) & (a['PULocationID'] != a['DOLocationID'])]\n",
    "    # Ensures the PULocationID and DOLocationID values are within the valid range of 1–263\n",
    "    a = a[(a['PULocationID'] >= 1) & (a['PULocationID'] <= 263)]\n",
    "    a = a[(a['DOLocationID'] >= 1) & (a['DOLocationID'] <= 263)]\n",
    "    # drop nan\n",
    "    a = a.dropna(subset=['trip_distance', 'PULocationID', 'DOLocationID'])  \n",
    "    # get sample\n",
    "    a = calculate_sample_size(a)\n",
    "    # Convert ID to lat lon\n",
    "    a = add_coordinates_to_taxi_data(a, loaded_taxi_zones)\n",
    "    # Filter by latitude\n",
    "    a = a[a['PUlat'].between(40.560445, 40.908524)] \n",
    "    a = a[a['DOlat'].between(40.560445, 40.908524)] \n",
    "    # Filter by longitude\n",
    "    a = a[a['PUlon'].between(-74.242330, -73.717047)] \n",
    "    a = a[a['DOlon'].between(-74.242330, -73.717047)]  \n",
    "    a = a.drop(['RatecodeID', 'store_and_fwd_flag', 'payment_type', \n",
    "             'extra'], axis=1)\n",
    "    # more clean step\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4205321b-197d-46b7-8316-d697111f0821",
   "metadata": {},
   "source": [
    "* Cleaning each file individually.\n",
    "* Merging all the cleaned files into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(parquet_urls):\n",
    "    all_taxi_dataframes = []\n",
    "    loaded_taxi_zones = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "    for parquet_url in tqdm(parquet_urls):\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month(parquet_url, loaded_taxi_zones)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        all_taxi_dataframes.append(dataframe.sort_values(by='tpep_pickup_datetime', ascending=True))  \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes, ignore_index=True)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c982d4-cef6-4b3a-aac4-6df9f1be8d4a",
   "metadata": {},
   "source": [
    "Return a cleaned and combined dataset of taxi trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_data():\n",
    "    taxi_path.sort()\n",
    "    taxi_data = get_and_clean_taxi_data(taxi_path)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "876bd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:47<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>PUlat</th>\n",
       "      <th>PUlon</th>\n",
       "      <th>DOlat</th>\n",
       "      <th>DOlon</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 00:56:39</td>\n",
       "      <td>2020-01-01 01:21:13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.712459</td>\n",
       "      <td>-73.998151</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 02:09:23</td>\n",
       "      <td>2020-01-01 02:24:08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:35:25</td>\n",
       "      <td>2020-01-01 03:06:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.761493</td>\n",
       "      <td>-73.919694</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 03:11:10</td>\n",
       "      <td>2020-01-01 03:23:52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.766238</td>\n",
       "      <td>-73.995135</td>\n",
       "      <td>40.841709</td>\n",
       "      <td>-73.941399</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 03:49:45</td>\n",
       "      <td>2020-01-01 03:59:46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.804334</td>\n",
       "      <td>-73.951292</td>\n",
       "      <td>40.818258</td>\n",
       "      <td>-73.940772</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2020-01-01 00:56:39   2020-01-01 01:21:13              2.0   \n",
       "1         1  2020-01-01 02:09:23   2020-01-01 02:24:08              3.0   \n",
       "2         2  2020-01-01 02:35:25   2020-01-01 03:06:56              1.0   \n",
       "3         2  2020-01-01 03:11:10   2020-01-01 03:23:52              6.0   \n",
       "4         1  2020-01-01 03:49:45   2020-01-01 03:59:46              2.0   \n",
       "\n",
       "   trip_distance  fare_amount  mta_tax  tip_amount  tolls_amount  \\\n",
       "0           3.80         16.5      0.5        0.00           0.0   \n",
       "1           3.30         13.0      0.5        3.35           0.0   \n",
       "2           6.82         25.5      0.5        5.86           0.0   \n",
       "3           6.91         21.0      0.5        4.96           0.0   \n",
       "4           1.40          8.5      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \\\n",
       "0                    0.3         20.30                   2.5          NaN   \n",
       "1                    0.3         20.15                   2.5          NaN   \n",
       "2                    0.3         35.16                   2.5          NaN   \n",
       "3                    0.3         29.76                   2.5          NaN   \n",
       "4                    0.3          9.80                   0.0          NaN   \n",
       "\n",
       "       PUlat      PUlon      DOlat      DOlon  Airport_fee  \n",
       "0  40.756729 -73.965146  40.712459 -73.998151          NaN  \n",
       "1  40.736824 -73.984052  40.775932 -73.946510          NaN  \n",
       "2  40.756729 -73.965146  40.761493 -73.919694          NaN  \n",
       "3  40.766238 -73.995135  40.841709 -73.941399          NaN  \n",
       "4  40.804334 -73.951292  40.818258 -73.940772          NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37c1b3-2c89-4970-8e2d-5a6df595e0b2",
   "metadata": {},
   "source": [
    "Adjust columns' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1886536-077a-4ea1-81d9-383634f1220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'VendorID': 'vendor_id',\n",
    "    'tpep_pickup_datetime': 'pickup_time',\n",
    "    'tpep_dropoff_datetime': 'dropoff_time',\n",
    "    'passenger_count': 'passenger_count',\n",
    "    'trip_distance': 'trip_distance',\n",
    "    'fare_amount': 'fare_amount',\n",
    "    'mta_tax': 'tax',\n",
    "    'tip_amount': 'tip',\n",
    "    'tolls_amount': 'tolls',\n",
    "    'improvement_surcharge' : 'imp_surcharge',\n",
    "    'total_amount': 'total_amount',\n",
    "    'congestion_surcharge':'con_surcharge',\n",
    "    'airport_fee': 'airport_fee',\n",
    "    'PUlat':'pickup_lat',\n",
    "    'PUlon':'pickup_lon',\n",
    "    'DOlat':'dropoff_lat',\n",
    "    'DOlon':'dropoff_lon',\n",
    "    'Airport_fee':'fee'\n",
    "}\n",
    "\n",
    "taxi_data = taxi_data.rename(columns=new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f775767-f1c0-44b8-aced-eb85beeeb988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tax</th>\n",
       "      <th>tip</th>\n",
       "      <th>tolls</th>\n",
       "      <th>imp_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>con_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 00:56:39</td>\n",
       "      <td>2020-01-01 01:21:13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.712459</td>\n",
       "      <td>-73.998151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 02:09:23</td>\n",
       "      <td>2020-01-01 02:24:08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:35:25</td>\n",
       "      <td>2020-01-01 03:06:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.761493</td>\n",
       "      <td>-73.919694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 03:11:10</td>\n",
       "      <td>2020-01-01 03:23:52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.766238</td>\n",
       "      <td>-73.995135</td>\n",
       "      <td>40.841709</td>\n",
       "      <td>-73.941399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 03:49:45</td>\n",
       "      <td>2020-01-01 03:59:46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.804334</td>\n",
       "      <td>-73.951292</td>\n",
       "      <td>40.818258</td>\n",
       "      <td>-73.940772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id         pickup_time        dropoff_time  passenger_count  \\\n",
       "0          1 2020-01-01 00:56:39 2020-01-01 01:21:13              2.0   \n",
       "1          1 2020-01-01 02:09:23 2020-01-01 02:24:08              3.0   \n",
       "2          2 2020-01-01 02:35:25 2020-01-01 03:06:56              1.0   \n",
       "3          2 2020-01-01 03:11:10 2020-01-01 03:23:52              6.0   \n",
       "4          1 2020-01-01 03:49:45 2020-01-01 03:59:46              2.0   \n",
       "\n",
       "   trip_distance  fare_amount  tax   tip  tolls  imp_surcharge  total_amount  \\\n",
       "0           3.80         16.5  0.5  0.00    0.0            0.3         20.30   \n",
       "1           3.30         13.0  0.5  3.35    0.0            0.3         20.15   \n",
       "2           6.82         25.5  0.5  5.86    0.0            0.3         35.16   \n",
       "3           6.91         21.0  0.5  4.96    0.0            0.3         29.76   \n",
       "4           1.40          8.5  0.5  0.00    0.0            0.3          9.80   \n",
       "\n",
       "   con_surcharge  airport_fee  pickup_lat  pickup_lon  dropoff_lat  \\\n",
       "0            2.5          NaN   40.756729  -73.965146    40.712459   \n",
       "1            2.5          NaN   40.736824  -73.984052    40.775932   \n",
       "2            2.5          NaN   40.756729  -73.965146    40.761493   \n",
       "3            2.5          NaN   40.766238  -73.995135    40.841709   \n",
       "4            0.0          NaN   40.804334  -73.951292    40.818258   \n",
       "\n",
       "   dropoff_lon  \n",
       "0   -73.998151  \n",
       "1   -73.946510  \n",
       "2   -73.919694  \n",
       "3   -73.941399  \n",
       "4   -73.940772  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9da7089-3f6b-4f93-a22e-76bf554daca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21934 entries, 0 to 21933\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   vendor_id        21934 non-null  int64         \n",
      " 1   pickup_time      21934 non-null  datetime64[ns]\n",
      " 2   dropoff_time     21934 non-null  datetime64[ns]\n",
      " 3   passenger_count  20795 non-null  float64       \n",
      " 4   trip_distance    21934 non-null  float64       \n",
      " 5   fare_amount      21934 non-null  float64       \n",
      " 6   tax              21934 non-null  float64       \n",
      " 7   tip              21934 non-null  float64       \n",
      " 8   tolls            21934 non-null  float64       \n",
      " 9   imp_surcharge    21934 non-null  float64       \n",
      " 10  total_amount     21934 non-null  float64       \n",
      " 11  con_surcharge    20795 non-null  float64       \n",
      " 12  airport_fee      8187 non-null   float64       \n",
      " 13  pickup_lat       21934 non-null  float64       \n",
      " 14  pickup_lon       21934 non-null  float64       \n",
      " 15  dropoff_lat      21934 non-null  float64       \n",
      " 16  dropoff_lon      21934 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(14), int64(1)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50c85e25-6416-4c16-b98c-09596cdc6865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tax</th>\n",
       "      <th>tip</th>\n",
       "      <th>tolls</th>\n",
       "      <th>imp_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>con_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21934.000000</td>\n",
       "      <td>20795.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>20795.000000</td>\n",
       "      <td>8187.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.718291</td>\n",
       "      <td>1.396778</td>\n",
       "      <td>4.616993</td>\n",
       "      <td>15.519664</td>\n",
       "      <td>0.492523</td>\n",
       "      <td>2.738133</td>\n",
       "      <td>0.448342</td>\n",
       "      <td>0.552694</td>\n",
       "      <td>22.656455</td>\n",
       "      <td>2.300313</td>\n",
       "      <td>0.083975</td>\n",
       "      <td>40.752857</td>\n",
       "      <td>-73.967122</td>\n",
       "      <td>40.755038</td>\n",
       "      <td>-73.970701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.449842</td>\n",
       "      <td>0.976673</td>\n",
       "      <td>164.542840</td>\n",
       "      <td>13.960149</td>\n",
       "      <td>0.079543</td>\n",
       "      <td>3.138831</td>\n",
       "      <td>1.856061</td>\n",
       "      <td>0.352648</td>\n",
       "      <td>17.752309</td>\n",
       "      <td>0.721166</td>\n",
       "      <td>0.316574</td>\n",
       "      <td>0.032189</td>\n",
       "      <td>0.045494</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.036873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-145.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-23.920000</td>\n",
       "      <td>-15.380000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-146.500000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.170887</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.960000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>17.160000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.185000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.959635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>24137.690000</td>\n",
       "      <td>172.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.780000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>40.897932</td>\n",
       "      <td>-73.735554</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vendor_id  passenger_count  trip_distance   fare_amount  \\\n",
       "count  21934.000000     20795.000000   21934.000000  21934.000000   \n",
       "mean       1.718291         1.396778       4.616993     15.519664   \n",
       "std        0.449842         0.976673     164.542840     13.960149   \n",
       "min        1.000000         0.000000       0.010000   -145.500000   \n",
       "25%        1.000000         1.000000       1.150000      7.500000   \n",
       "50%        2.000000         1.000000       1.870000     11.000000   \n",
       "75%        2.000000         1.000000       3.500000     17.700000   \n",
       "max        2.000000         6.000000   24137.690000    172.400000   \n",
       "\n",
       "                tax           tip         tolls  imp_surcharge  total_amount  \\\n",
       "count  21934.000000  21934.000000  21934.000000   21934.000000  21934.000000   \n",
       "mean       0.492523      2.738133      0.448342       0.552694     22.656455   \n",
       "std        0.079543      3.138831      1.856061       0.352648     17.752309   \n",
       "min       -0.500000    -23.920000    -15.380000      -1.000000   -146.500000   \n",
       "25%        0.500000      0.000000      0.000000       0.300000     12.960000   \n",
       "50%        0.500000      2.200000      0.000000       0.300000     17.160000   \n",
       "75%        0.500000      3.500000      0.000000       1.000000     25.185000   \n",
       "max        0.500000     50.000000     46.150000       1.000000    187.780000   \n",
       "\n",
       "       con_surcharge  airport_fee    pickup_lat    pickup_lon   dropoff_lat  \\\n",
       "count   20795.000000  8187.000000  21934.000000  21934.000000  21934.000000   \n",
       "mean        2.300313     0.083975     40.752857    -73.967122     40.755038   \n",
       "std         0.721166     0.316574      0.032189      0.045494      0.033799   \n",
       "min        -2.500000    -1.250000     40.576961    -74.170887     40.576961   \n",
       "25%         2.500000     0.000000     40.740337    -73.989845     40.740337   \n",
       "50%         2.500000     0.000000     40.756729    -73.977698     40.758028   \n",
       "75%         2.500000     0.000000     40.773633    -73.965146     40.775932   \n",
       "max         2.500000     1.250000     40.897932    -73.735554     40.899529   \n",
       "\n",
       "        dropoff_lon  \n",
       "count  21934.000000  \n",
       "mean     -73.970701  \n",
       "std        0.036873  \n",
       "min      -74.174000  \n",
       "25%      -73.989845  \n",
       "50%      -73.977698  \n",
       "75%      -73.959635  \n",
       "max      -73.726655  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea169042-5c3f-485d-8dcd-fd1284cc7b1d",
   "metadata": {},
   "source": [
    "1. Load Data: Reads the Parquet file from the specified url into a pandas DataFrame.\n",
    "\n",
    "2. Filter by License: Retains only trips associated with hvfhs_license_num == 'HV0003' (representing Uber data).\n",
    "\n",
    "3. Initial Filtering: Excludes trips with non-positive trip distances.\n",
    " - Removes trips where the pickup (PULocationID) and drop-off (DOLocationID) locations are the same.\n",
    " - Retains only rows where PULocationID and DOLocationID are within the valid range of 1–263.\n",
    "\n",
    "4. Handle Missing Data: Drops rows with missing values in trip_distance, PULocationID, or DOLocationID.\n",
    "\n",
    "5. Sampling: Reduces the dataset size by calculating and selecting an appropriate sample using calculate_sample_size().\n",
    "\n",
    "6. Add Geographic Coordinates: Enriches the dataset by adding latitude and longitude columns for both pickup and drop-off locations using the add_coordinates_to_taxi_data() function.\n",
    "\n",
    "7. Filter by Geographic Boundaries: Ensures that the latitude and longitude of both pickup and drop-off locations fall within specified geographic boundaries.\n",
    "\n",
    "8. Drop Unnecessary Columns: Removes columns irrelevant for further analysis:  driver_pay, shared_request_flag, shared_match_flag, access_a_ride_flag, wav_request_flag, wav_match_flag, bcf, airport_fee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07574983-f41d-4cd6-8f70-489493089b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_month(url, loaded_taxi_zones):\n",
    "    # uber\n",
    "    a = pd.read_parquet(url)\n",
    "    a = a[(a['hvfhs_license_num'] == 'HV0003')]\n",
    "    a = a.rename(columns={'trip_miles': 'trip_distance'})\n",
    "    a = a[(a['trip_distance'] > 0) & (a['PULocationID'] != a['DOLocationID'])]\n",
    "    a = a[(a['PULocationID'] >= 1) & (a['PULocationID'] <= 263)]\n",
    "    a = a[(a['DOLocationID'] >= 1) & (a['DOLocationID'] <= 263)]\n",
    "    a = a.dropna(subset=['trip_distance', 'PULocationID', 'DOLocationID'])  \n",
    "    a = calculate_sample_size(a)\n",
    "    a = add_coordinates_to_taxi_data(a, loaded_taxi_zones)\n",
    "    # Filter by latitude\n",
    "    a = a[a['PUlat'].between(40.560445, 40.908524)] \n",
    "    a = a[a['DOlat'].between(40.560445, 40.908524)] \n",
    "    # Filter by longitude\n",
    "    a = a[a['PUlon'].between(-74.242330, -73.717047)] \n",
    "    a = a[a['DOlon'].between(-74.242330, -73.717047)]  \n",
    "    a = a.drop([ 'driver_pay', \n",
    "            'shared_request_flag', 'shared_match_flag', \n",
    "            'access_a_ride_flag', 'wav_request_flag', \n",
    "            'wav_match_flag','bcf','airport_fee'], axis=1)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567f7e2-93f8-4245-9c1a-b3df4dcb53eb",
   "metadata": {},
   "source": [
    "Processes and consolidates Uber trip data from multiple Parquet files into a single cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b3d85ff-313c-41a2-9a46-261a9a2bb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_data(parquet_urls):\n",
    "    all_uber_dataframes = []\n",
    "    loaded_taxi_zones = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "    for parquet_url in tqdm(parquet_urls):\n",
    "        dataframe = get_and_clean_uber_month(parquet_url, loaded_taxi_zones)\n",
    "        all_uber_dataframes.append(dataframe.sort_values(by='pickup_datetime', ascending=True))  \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    uber_data = pd.concat(all_uber_dataframes, ignore_index=True)\n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    hvfhv_path.sort()\n",
    "    taxi_data = get_and_clean_uber_data(hvfhv_path)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [08:35<00:00,  9.05s/it]\n"
     ]
    }
   ],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>tips</th>\n",
       "      <th>PUlat</th>\n",
       "      <th>PUlon</th>\n",
       "      <th>DOlat</th>\n",
       "      <th>DOlon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02872</td>\n",
       "      <td>B02872</td>\n",
       "      <td>2020-01-01 00:35:28</td>\n",
       "      <td>2020-01-01 00:40:04</td>\n",
       "      <td>2020-01-01 00:42:54</td>\n",
       "      <td>2020-01-01 00:58:30</td>\n",
       "      <td>2.01</td>\n",
       "      <td>936</td>\n",
       "      <td>18.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.658744</td>\n",
       "      <td>-73.947442</td>\n",
       "      <td>40.652365</td>\n",
       "      <td>-73.922251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02889</td>\n",
       "      <td>B02889</td>\n",
       "      <td>2020-01-01 04:20:12</td>\n",
       "      <td>2020-01-01 04:20:47</td>\n",
       "      <td>2020-01-01 04:25:07</td>\n",
       "      <td>2020-01-01 04:44:12</td>\n",
       "      <td>4.71</td>\n",
       "      <td>1145</td>\n",
       "      <td>36.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.715370</td>\n",
       "      <td>-73.936793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02836</td>\n",
       "      <td>B02836</td>\n",
       "      <td>2020-01-01 04:45:28</td>\n",
       "      <td>2020-01-01 04:48:10</td>\n",
       "      <td>2020-01-01 04:49:22</td>\n",
       "      <td>2020-01-01 05:08:37</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1155</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "      <td>40.695338</td>\n",
       "      <td>-73.986086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02835</td>\n",
       "      <td>B02835</td>\n",
       "      <td>2020-01-01 06:15:30</td>\n",
       "      <td>2020-01-01 06:19:21</td>\n",
       "      <td>2020-01-01 06:20:19</td>\n",
       "      <td>2020-01-01 06:29:43</td>\n",
       "      <td>1.94</td>\n",
       "      <td>564</td>\n",
       "      <td>10.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.652365</td>\n",
       "      <td>-73.922251</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02883</td>\n",
       "      <td>B02883</td>\n",
       "      <td>2020-01-01 16:06:43</td>\n",
       "      <td>2020-01-01 16:11:01</td>\n",
       "      <td>2020-01-01 16:11:14</td>\n",
       "      <td>2020-01-01 16:47:16</td>\n",
       "      <td>17.51</td>\n",
       "      <td>2162</td>\n",
       "      <td>76.34</td>\n",
       "      <td>6.12</td>\n",
       "      <td>7.32</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.646985</td>\n",
       "      <td>-73.786533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0            HV0003               B02872               B02872   \n",
       "1            HV0003               B02889               B02889   \n",
       "2            HV0003               B02836               B02836   \n",
       "3            HV0003               B02835               B02835   \n",
       "4            HV0003               B02883               B02883   \n",
       "\n",
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2020-01-01 00:35:28 2020-01-01 00:40:04 2020-01-01 00:42:54   \n",
       "1 2020-01-01 04:20:12 2020-01-01 04:20:47 2020-01-01 04:25:07   \n",
       "2 2020-01-01 04:45:28 2020-01-01 04:48:10 2020-01-01 04:49:22   \n",
       "3 2020-01-01 06:15:30 2020-01-01 06:19:21 2020-01-01 06:20:19   \n",
       "4 2020-01-01 16:06:43 2020-01-01 16:11:01 2020-01-01 16:11:14   \n",
       "\n",
       "     dropoff_datetime  trip_distance  trip_time  base_passenger_fare  tolls  \\\n",
       "0 2020-01-01 00:58:30           2.01        936                18.67   0.00   \n",
       "1 2020-01-01 04:44:12           4.71       1145                36.90   0.00   \n",
       "2 2020-01-01 05:08:37           4.07       1155                 8.20   0.00   \n",
       "3 2020-01-01 06:29:43           1.94        564                10.51   0.00   \n",
       "4 2020-01-01 16:47:16          17.51       2162                76.34   6.12   \n",
       "\n",
       "   sales_tax  congestion_surcharge  tips      PUlat      PUlon      DOlat  \\\n",
       "0       1.66                  0.00   0.0  40.658744 -73.947442  40.652365   \n",
       "1       3.27                  2.75   0.0  40.718938 -73.990896  40.715370   \n",
       "2       0.73                  0.00   0.0  40.674469 -73.939287  40.695338   \n",
       "3       0.93                  0.00   0.0  40.652365 -73.922251  40.674469   \n",
       "4       7.32                  2.75   0.0  40.758028 -73.977698  40.646985   \n",
       "\n",
       "       DOlon  \n",
       "0 -73.922251  \n",
       "1 -73.936793  \n",
       "2 -73.986086  \n",
       "3 -73.939287  \n",
       "4 -73.786533  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "422ca3b4-776b-458c-94d4-15607c2d4abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'hvfhs_license_num': 'license_number',\n",
    "    'dispatching_base_num': 'dispatch_base',\n",
    "    'originating_base_num': 'origin_base',\n",
    "    'request_datetime': 'request_time',\n",
    "    'on_scene_datetime': 'on_scene_time',\n",
    "    'pickup_datetime': 'pickup_time',\n",
    "    'dropoff_datetime': 'dropoff_time',\n",
    "    'trip_distance': 'trip_distance',\n",
    "    'trip_time': 'trip_duration',\n",
    "    'base_passenger_fare':'fare_amount',\n",
    "    'tolls': 'tolls',\n",
    "    'sales_tax': 'tax',\n",
    "    'congestion_surcharge': 'con_surcharge',\n",
    "    'tips': 'tips',\n",
    "    'PUlat': 'pickup_lat',\n",
    "    'PUlon': 'pickup_lon',\n",
    "    'DOlat': 'dropoff_lat',\n",
    "    'DOlon': 'dropoff_lon'\n",
    "}\n",
    "\n",
    "uber_data = uber_data.rename(columns=new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8900b53a-249e-4136-bcbe-517cd52c8a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>license_number</th>\n",
       "      <th>dispatch_base</th>\n",
       "      <th>origin_base</th>\n",
       "      <th>request_time</th>\n",
       "      <th>on_scene_time</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tolls</th>\n",
       "      <th>tax</th>\n",
       "      <th>con_surcharge</th>\n",
       "      <th>tips</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02872</td>\n",
       "      <td>B02872</td>\n",
       "      <td>2020-01-01 00:35:28</td>\n",
       "      <td>2020-01-01 00:40:04</td>\n",
       "      <td>2020-01-01 00:42:54</td>\n",
       "      <td>2020-01-01 00:58:30</td>\n",
       "      <td>2.01</td>\n",
       "      <td>936</td>\n",
       "      <td>18.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.658744</td>\n",
       "      <td>-73.947442</td>\n",
       "      <td>40.652365</td>\n",
       "      <td>-73.922251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02889</td>\n",
       "      <td>B02889</td>\n",
       "      <td>2020-01-01 04:20:12</td>\n",
       "      <td>2020-01-01 04:20:47</td>\n",
       "      <td>2020-01-01 04:25:07</td>\n",
       "      <td>2020-01-01 04:44:12</td>\n",
       "      <td>4.71</td>\n",
       "      <td>1145</td>\n",
       "      <td>36.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.715370</td>\n",
       "      <td>-73.936793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02836</td>\n",
       "      <td>B02836</td>\n",
       "      <td>2020-01-01 04:45:28</td>\n",
       "      <td>2020-01-01 04:48:10</td>\n",
       "      <td>2020-01-01 04:49:22</td>\n",
       "      <td>2020-01-01 05:08:37</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1155</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "      <td>40.695338</td>\n",
       "      <td>-73.986086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02835</td>\n",
       "      <td>B02835</td>\n",
       "      <td>2020-01-01 06:15:30</td>\n",
       "      <td>2020-01-01 06:19:21</td>\n",
       "      <td>2020-01-01 06:20:19</td>\n",
       "      <td>2020-01-01 06:29:43</td>\n",
       "      <td>1.94</td>\n",
       "      <td>564</td>\n",
       "      <td>10.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.652365</td>\n",
       "      <td>-73.922251</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02883</td>\n",
       "      <td>B02883</td>\n",
       "      <td>2020-01-01 16:06:43</td>\n",
       "      <td>2020-01-01 16:11:01</td>\n",
       "      <td>2020-01-01 16:11:14</td>\n",
       "      <td>2020-01-01 16:47:16</td>\n",
       "      <td>17.51</td>\n",
       "      <td>2162</td>\n",
       "      <td>76.34</td>\n",
       "      <td>6.12</td>\n",
       "      <td>7.32</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.646985</td>\n",
       "      <td>-73.786533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  license_number dispatch_base origin_base        request_time  \\\n",
       "0         HV0003        B02872      B02872 2020-01-01 00:35:28   \n",
       "1         HV0003        B02889      B02889 2020-01-01 04:20:12   \n",
       "2         HV0003        B02836      B02836 2020-01-01 04:45:28   \n",
       "3         HV0003        B02835      B02835 2020-01-01 06:15:30   \n",
       "4         HV0003        B02883      B02883 2020-01-01 16:06:43   \n",
       "\n",
       "        on_scene_time         pickup_time        dropoff_time  trip_distance  \\\n",
       "0 2020-01-01 00:40:04 2020-01-01 00:42:54 2020-01-01 00:58:30           2.01   \n",
       "1 2020-01-01 04:20:47 2020-01-01 04:25:07 2020-01-01 04:44:12           4.71   \n",
       "2 2020-01-01 04:48:10 2020-01-01 04:49:22 2020-01-01 05:08:37           4.07   \n",
       "3 2020-01-01 06:19:21 2020-01-01 06:20:19 2020-01-01 06:29:43           1.94   \n",
       "4 2020-01-01 16:11:01 2020-01-01 16:11:14 2020-01-01 16:47:16          17.51   \n",
       "\n",
       "   trip_duration  fare_amount  tolls   tax  con_surcharge  tips  pickup_lat  \\\n",
       "0            936        18.67   0.00  1.66           0.00   0.0   40.658744   \n",
       "1           1145        36.90   0.00  3.27           2.75   0.0   40.718938   \n",
       "2           1155         8.20   0.00  0.73           0.00   0.0   40.674469   \n",
       "3            564        10.51   0.00  0.93           0.00   0.0   40.652365   \n",
       "4           2162        76.34   6.12  7.32           2.75   0.0   40.758028   \n",
       "\n",
       "   pickup_lon  dropoff_lat  dropoff_lon  \n",
       "0  -73.947442    40.652365   -73.922251  \n",
       "1  -73.990896    40.715370   -73.936793  \n",
       "2  -73.939287    40.695338   -73.986086  \n",
       "3  -73.922251    40.674469   -73.939287  \n",
       "4  -73.977698    40.646985   -73.786533  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74d783db-e527-4847-bf70-2d7428ea3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21851 entries, 0 to 21850\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   license_number  21851 non-null  object        \n",
      " 1   dispatch_base   21851 non-null  object        \n",
      " 2   origin_base     21846 non-null  object        \n",
      " 3   request_time    21851 non-null  datetime64[ns]\n",
      " 4   on_scene_time   21851 non-null  datetime64[ns]\n",
      " 5   pickup_time     21851 non-null  datetime64[ns]\n",
      " 6   dropoff_time    21851 non-null  datetime64[ns]\n",
      " 7   trip_distance   21851 non-null  float64       \n",
      " 8   trip_duration   21851 non-null  int64         \n",
      " 9   fare_amount     21851 non-null  float64       \n",
      " 10  tolls           21851 non-null  float64       \n",
      " 11  tax             21851 non-null  float64       \n",
      " 12  con_surcharge   21851 non-null  float64       \n",
      " 13  tips            21851 non-null  float64       \n",
      " 14  pickup_lat      21851 non-null  float64       \n",
      " 15  pickup_lon      21851 non-null  float64       \n",
      " 16  dropoff_lat     21851 non-null  float64       \n",
      " 17  dropoff_lon     21851 non-null  float64       \n",
      "dtypes: datetime64[ns](4), float64(10), int64(1), object(3)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fddeb14-cd70-4e83-8f93-974642c3bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tolls</th>\n",
       "      <th>tax</th>\n",
       "      <th>con_surcharge</th>\n",
       "      <th>tips</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.651595</td>\n",
       "      <td>1120.405473</td>\n",
       "      <td>21.971942</td>\n",
       "      <td>0.714933</td>\n",
       "      <td>1.964367</td>\n",
       "      <td>1.106185</td>\n",
       "      <td>0.846985</td>\n",
       "      <td>40.739567</td>\n",
       "      <td>-73.936109</td>\n",
       "      <td>40.739079</td>\n",
       "      <td>-73.936559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.370277</td>\n",
       "      <td>729.895150</td>\n",
       "      <td>15.577976</td>\n",
       "      <td>2.736384</td>\n",
       "      <td>1.437378</td>\n",
       "      <td>1.343959</td>\n",
       "      <td>2.539146</td>\n",
       "      <td>0.067755</td>\n",
       "      <td>0.063597</td>\n",
       "      <td>0.068204</td>\n",
       "      <td>0.066896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.210000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>-15.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.170887</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.730000</td>\n",
       "      <td>614.500000</td>\n",
       "      <td>11.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.694428</td>\n",
       "      <td>-73.985156</td>\n",
       "      <td>40.691831</td>\n",
       "      <td>-73.984196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.060000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>17.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.739496</td>\n",
       "      <td>-73.949540</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.948891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.920000</td>\n",
       "      <td>1419.000000</td>\n",
       "      <td>27.225000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.775965</td>\n",
       "      <td>-73.900316</td>\n",
       "      <td>40.775965</td>\n",
       "      <td>-73.899735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37.470000</td>\n",
       "      <td>8173.000000</td>\n",
       "      <td>204.350000</td>\n",
       "      <td>51.350000</td>\n",
       "      <td>17.190000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>43.670000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trip_distance  trip_duration   fare_amount         tolls           tax  \\\n",
       "count   21851.000000   21851.000000  21851.000000  21851.000000  21851.000000   \n",
       "mean        4.651595    1120.405473     21.971942      0.714933      1.964367   \n",
       "std         4.370277     729.895150     15.577976      2.736384      1.437378   \n",
       "min         0.210000      68.000000    -15.760000      0.000000      0.000000   \n",
       "25%         1.730000     614.500000     11.540000      0.000000      1.000000   \n",
       "50%         3.060000     932.000000     17.690000      0.000000      1.560000   \n",
       "75%         5.920000    1419.000000     27.225000      0.000000      2.450000   \n",
       "max        37.470000    8173.000000    204.350000     51.350000     17.190000   \n",
       "\n",
       "       con_surcharge          tips    pickup_lat    pickup_lon   dropoff_lat  \\\n",
       "count   21851.000000  21851.000000  21851.000000  21851.000000  21851.000000   \n",
       "mean        1.106185      0.846985     40.739567    -73.936109     40.739079   \n",
       "std         1.343959      2.539146      0.067755      0.063597      0.068204   \n",
       "min         0.000000      0.000000     40.561994    -74.170887     40.561994   \n",
       "25%         0.000000      0.000000     40.694428    -73.985156     40.691831   \n",
       "50%         0.000000      0.000000     40.739496    -73.949540     40.740337   \n",
       "75%         2.750000      0.000000     40.775965    -73.900316     40.775965   \n",
       "max         2.750000     43.670000     40.899529    -73.726655     40.899529   \n",
       "\n",
       "        dropoff_lon  \n",
       "count  21851.000000  \n",
       "mean     -73.936559  \n",
       "std        0.066896  \n",
       "min      -74.174000  \n",
       "25%      -73.984196  \n",
       "50%      -73.948891  \n",
       "75%      -73.899735  \n",
       "max      -73.726655  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069f9d0",
   "metadata": {},
   "source": [
    "Retrieves and sorts all weather CSV files, filtering for files associated with the years 2020 to 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19d37461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather_csvs(directory):\n",
    "    # List to store file paths for all weather CSVs from 2020 to 2024\n",
    "    weather_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            for year in range(2020, 2025):\n",
    "                if str(year) in filename:\n",
    "                    weather_files.append(os.path.join(directory, filename))  \n",
    "    weather_files.sort()\n",
    "    return weather_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22825c7b",
   "metadata": {},
   "source": [
    "Processes a group of precipitation data, handling special cases like \"trace\" values ('T') and summing numeric values while ensuring robust handling of non-numeric or missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8289703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_precipitation(group):\n",
    "        def safe_float_conversion(x):\n",
    "            try:\n",
    "                return float(x)\n",
    "            except ValueError:\n",
    "                return 0    \n",
    "        if all(x == 'T' for x in group):\n",
    "            return 'T'       \n",
    "        elif 'T' in group.values:\n",
    "            numeric_sum = sum(safe_float_conversion(x) for x in group if x not in ['T', np.nan])\n",
    "            return numeric_sum if numeric_sum > 0 else 'T'       \n",
    "        else:\n",
    "            return sum(safe_float_conversion(x) for x in group if pd.notna(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d0202",
   "metadata": {},
   "source": [
    "Processes hourly weather data from a CSV file, cleans it, and ensures it is aggregated, consistent, and complete for time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3151718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # choose column\n",
    "    hourly_column = ['DATE', 'HourlyPrecipitation', 'HourlyWindSpeed']\n",
    "    df_tmp = df[hourly_column]\n",
    "    hourly_data = df_tmp[~df_tmp['DATE'].str.contains(\"T23:59:00\", na=False)]\n",
    "    hourly_data['DATE'] = pd.to_datetime(hourly_data['DATE'])\n",
    "   \n",
    "    hourly_data['DATE'] = pd.to_datetime(hourly_data['DATE'])\n",
    "    hourly_data['HourGroup'] = hourly_data['DATE'].dt.floor('H')\n",
    "    hourly_data['HourlyPrecipitation'] = hourly_data['HourlyPrecipitation'].replace(np.nan, 0)\n",
    "    \n",
    "    \n",
    "    aggregated = hourly_data.groupby('HourGroup').agg(\n",
    "        HourlyPrecipitation=('HourlyPrecipitation', process_precipitation),\n",
    "        HourlyWindSpeed=('HourlyWindSpeed', lambda x: x.mean() if len(x) > 0 else 0)\n",
    "    ).reset_index()\n",
    "    \n",
    "    \n",
    "    aggregated['DATE'] = aggregated['HourGroup'] + pd.Timedelta(minutes=51)\n",
    "    aggregated = aggregated.drop(columns=['HourGroup'])\n",
    "    aggregated = aggregated[['DATE'] + [col for col in aggregated.columns if col != 'DATE']]\n",
    "    \n",
    "    \n",
    "    year = aggregated['DATE'].dt.year.min()  \n",
    "    max_date = aggregated['DATE'].max()\n",
    "    start_date = f\"{year}-01-01 23:51:00\"   \n",
    "    end_date = max_date    \n",
    "    full_date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "    missing_dates = set(full_date_range) - set(aggregated['DATE'])\n",
    "    if missing_dates: \n",
    "        for missing_date in sorted(missing_dates):  \n",
    "            prev_hour = missing_date - pd.Timedelta(hours=1)\n",
    "            if prev_hour in set(aggregated['DATE']):\n",
    "                prev_data = aggregated[aggregated['DATE'] == prev_hour].iloc[0].copy()\n",
    "                prev_data['DATE'] = missing_date\n",
    "                aggregated = pd.concat([aggregated, pd.DataFrame([prev_data])], ignore_index=True)\n",
    "    hourly_data = aggregated.sort_values(by='DATE').reset_index(drop=True)\n",
    "    return hourly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32979b98",
   "metadata": {},
   "source": [
    "Processes daily weather data from a CSV file, ensures its completeness, and imputes missing data by leveraging hourly precipitation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19b2402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file,hourly_data):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    daily_column = ['DATE', 'DailyAverageWindSpeed', \n",
    "                'DailyPrecipitation', 'DailySnowfall', \n",
    "                'DailySustainedWindSpeed', 'DailyWeather']\n",
    "    df_tmp = df[daily_column]\n",
    "    daily_data = df_tmp[df_tmp['DATE'].str.contains(\"T23:59:00\", na=False)]\n",
    "    daily_data = daily_data.groupby('DATE', as_index=False).first()\n",
    "    daily_data['DATE'] = pd.to_datetime(daily_data['DATE'])\n",
    "    \n",
    "    if daily_data.shape[0] != 365 and daily_data.shape[0] != 366 and 360 <= daily_data.shape[0]:\n",
    "        year = daily_data['DATE'].dt.year.min()  \n",
    "        start_date = f\"{year}-01-01 23:59:00\"\n",
    "        end_date = f\"{year}-12-31 23:59:00\"\n",
    "        full_date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "        missing_dates = set(full_date_range) - set(daily_data['DATE'])\n",
    "        \n",
    "        if missing_dates:\n",
    "            new_rows = []\n",
    "            for missing_date in sorted(missing_dates):\n",
    "                previous_valid_date = daily_data[daily_data['DATE'] < missing_date].iloc[-1]\n",
    "                new_row = previous_valid_date.copy()\n",
    "                new_row['DATE'] = missing_date\n",
    "    \n",
    "                precipitation_sum = hourly_data[hourly_data['DATE'].dt.date == missing_date.date()]['HourlyPrecipitation'].sum()\n",
    "                new_row['DailyPrecipitation'] = precipitation_sum\n",
    "                new_rows.append(new_row)\n",
    "            daily_data = pd.concat([daily_data, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "            daily_data.sort_values(by='DATE', inplace=True)\n",
    "    return daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa6921",
   "metadata": {},
   "source": [
    "Return two DataFrames:\n",
    "\n",
    "hourly_data: Contains consolidated hourly weather data.\n",
    "daily_data: Contains consolidated daily weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf6bf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    weather_csv_files = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "        \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file, hourly_dataframe)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "400ae2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7007c268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATE HourlyPrecipitation  HourlyWindSpeed\n",
       "0 2020-01-01 00:51:00                 0.0              8.0\n",
       "1 2020-01-01 01:51:00                 0.0              8.0\n",
       "2 2020-01-01 02:51:00                 0.0             14.0\n",
       "3 2020-01-01 03:51:00                 0.0             11.0\n",
       "4 2020-01-01 04:51:00                 0.0              6.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85ba8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'DATE': 'datetime',\n",
    "    'HourlyPrecipitation': 'precipitation',\n",
    "    'HourlyWindSpeed': 'windspeed'\n",
    "}\n",
    "\n",
    "hourly_weather_data = hourly_weather_data.rename(columns=new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b4af81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime precipitation  windspeed\n",
       "0 2020-01-01 00:51:00           0.0        8.0\n",
       "1 2020-01-01 01:51:00           0.0        8.0\n",
       "2 2020-01-01 02:51:00           0.0       14.0\n",
       "3 2020-01-01 03:51:00           0.0       11.0\n",
       "4 2020-01-01 04:51:00           0.0        6.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6a4d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42163 entries, 0 to 7098\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   datetime       42163 non-null  datetime64[ns]\n",
      " 1   precipitation  42163 non-null  object        \n",
      " 2   windspeed      38712 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "hourly_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffe2c54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38712.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.103946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.449381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2237.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          windspeed\n",
       "count  38712.000000\n",
       "mean       5.103946\n",
       "std       16.449381\n",
       "min        0.000000\n",
       "25%        3.000000\n",
       "50%        5.000000\n",
       "75%        7.000000\n",
       "max     2237.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc2892f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>DailySnowfall</th>\n",
       "      <th>DailySustainedWindSpeed</th>\n",
       "      <th>DailyWeather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 23:59:00</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02 23:59:00</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03 23:59:00</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>RA BR HZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04 23:59:00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>RA FG BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05 23:59:00</td>\n",
       "      <td>11.3</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATE  DailyAverageWindSpeed DailyPrecipitation DailySnowfall  \\\n",
       "0 2020-01-01 23:59:00                    8.6               0.00           0.0   \n",
       "1 2020-01-02 23:59:00                    5.4               0.00           0.0   \n",
       "2 2020-01-03 23:59:00                    3.4               0.15           0.0   \n",
       "3 2020-01-04 23:59:00                    4.4               0.27           0.0   \n",
       "4 2020-01-05 23:59:00                   11.3                  T           0.0   \n",
       "\n",
       "  DailySustainedWindSpeed DailyWeather  \n",
       "0                    17.0         None  \n",
       "1                    13.0         None  \n",
       "2                    10.0     RA BR HZ  \n",
       "3                    15.0     RA FG BR  \n",
       "4                    25.0           RA  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ca6b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'DATE': 'datetime',\n",
    "    'DailyAverageWindSpeed': 'avg_windspeed',\n",
    "    'DailyPrecipitation': 'precipitation',\n",
    "    'DailySnowfall': 'snowfall',\n",
    "    'DailySustainedWindSpeed': 'sustained_windspeed',\n",
    "    'DailyWeather': 'daily_weather'\n",
    "}\n",
    "\n",
    "daily_weather_data = daily_weather_data.rename(columns=new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a3187eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>avg_windspeed</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>sustained_windspeed</th>\n",
       "      <th>daily_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 23:59:00</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02 23:59:00</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03 23:59:00</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>RA BR HZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04 23:59:00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>RA FG BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05 23:59:00</td>\n",
       "      <td>11.3</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  avg_windspeed precipitation snowfall  \\\n",
       "0 2020-01-01 23:59:00            8.6          0.00      0.0   \n",
       "1 2020-01-02 23:59:00            5.4          0.00      0.0   \n",
       "2 2020-01-03 23:59:00            3.4          0.15      0.0   \n",
       "3 2020-01-04 23:59:00            4.4          0.27      0.0   \n",
       "4 2020-01-05 23:59:00           11.3             T      0.0   \n",
       "\n",
       "  sustained_windspeed daily_weather  \n",
       "0                17.0          None  \n",
       "1                13.0          None  \n",
       "2                10.0      RA BR HZ  \n",
       "3                15.0      RA FG BR  \n",
       "4                25.0            RA  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3de3d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1756 entries, 0 to 294\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   datetime             1756 non-null   datetime64[ns]\n",
      " 1   avg_windspeed        1698 non-null   float64       \n",
      " 2   precipitation        1756 non-null   object        \n",
      " 3   snowfall             1751 non-null   object        \n",
      " 4   sustained_windspeed  1756 non-null   object        \n",
      " 5   daily_weather        831 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(4)\n",
      "memory usage: 96.0+ KB\n"
     ]
    }
   ],
   "source": [
    "daily_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87b1ffdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1698.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.338815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_windspeed\n",
       "count    1698.000000\n",
       "mean        5.001590\n",
       "std         2.338815\n",
       "min         0.600000\n",
       "25%         3.200000\n",
       "50%         4.600000\n",
       "75%         6.375000\n",
       "max        14.200000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# execute query either via sqlalchemy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m con:\n\u001b[1;32m      3\u001b[0m     results \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mexecute(db\u001b[38;5;241m.\u001b[39mtext(QUERY_1))\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m      4\u001b[0m results\n",
      "\u001b[0;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_1)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "pd.read_sql(QUERY_1, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
