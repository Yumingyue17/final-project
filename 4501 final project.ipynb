{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "058392ff-2eae-49ae-85d6-a228fc65d0ee",
   "metadata": {},
   "source": [
    "# 4501 final project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import geopandas as gpd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as pltx\n",
    "from urllib.parse import urljoin\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TLC_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"weather\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\"\n",
    "\n",
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b58c84-7d3e-4a21-ae40-0444edeb6ec4",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b24433-dd3d-4cce-84d6-211285024a57",
   "metadata": {},
   "source": [
    "Define a function download_file(link, save_dir) that efficiently download files ensuring that no duplicate downloads occur if the file already exists in the target directory and Saves the file in chunks of 8192 bytes to avoid memory overload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4988e20-4616-4cc8-800d-83a5e9fa6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local directory to save downloaded files\n",
    "download_dir = \"./nyc_taxi_data\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Function to download a file\n",
    "def download_file(link, save_dir):\n",
    "    file_name = link.split(\"/\")[-1]\n",
    "    file_path = os.path.join(save_dir, file_name)\n",
    "    # Skip download if the file already exists\n",
    "    if not os.path.exists(file_path):  \n",
    "        print(f\"Downloading {file_name}...\")\n",
    "        response = requests.get(link, stream=True)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Saved to {file_path}\")\n",
    "    else:\n",
    "        print(f\"{file_name} already exists. Skipping download.\")\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3cdb74-9a0b-479d-acd9-5f3349ef1dee",
   "metadata": {},
   "source": [
    "* Scraping a webpage for links to Yellow Taxi and HVFHV Parquet data files.\n",
    "* Downloading only the relevant files based on naming patterns and storing them locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d78db7-4e2d-4dc8-9303-3526bf48a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow_tripdata_2024-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2024-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2024-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-10.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-10.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-11.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-11.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2023-12.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2023-12.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-10.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-10.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-11.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-11.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-12.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-12.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-10.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-10.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-11.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-11.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-12.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-12.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-10.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-10.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-11.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-11.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2020-12.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2020-12.parquet already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Fetch the webpage content\n",
    "response = requests.get(TLC_URL)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "else:\n",
    "    raise Exception(\"Failed to fetch the TLC page.\")\n",
    "\n",
    "# Regular expressions to match Yellow Taxi and HVFHV links\n",
    "yellow_taxi_regex = re.compile(r\"yellow_tripdata_(202[0-4])-(0[1-9]|1[0-2])\\.parquet\", re.IGNORECASE)\n",
    "hvfhv_regex = re.compile(r\"fhvhv_tripdata_(202[0-4])-(0[1-9]|1[0-2])\\.parquet\", re.IGNORECASE)\n",
    "\n",
    "# Find all links on the page\n",
    "links = soup.find_all('a', href=True)\n",
    "\n",
    "# File path\n",
    "taxi_path = []\n",
    "hvfhv_path = []\n",
    "\n",
    "# Filter and download Yellow Taxi and HVFHV Parquet files\n",
    "taxi_path, hvfhv_path = [], []\n",
    "for link in soup.find_all(\"a\", href=True):\n",
    "    url = urljoin(\"https://www1.nyc.gov\", link[\"href\"].strip())\n",
    "    if yellow_taxi_regex.search(url):\n",
    "        taxi_path.append(download_file(url, download_dir))\n",
    "    elif hvfhv_regex.search(url):\n",
    "        hvfhv_path.append(download_file(url, download_dir))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a9aad-c9a8-4ab0-9fe2-1e327df9123c",
   "metadata": {},
   "source": [
    "* The first function (load_taxi_zones) processes and prepares taxi zone data from a shapefile for geospatial analysis.\n",
    "* The second function (lookup_coords_for_taxi_zone_id) finds the latitude and longitude coordinates of a taxi zone based on its LocationID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(shapefile_path):\n",
    "    taxi_zones = gpd.read_file(shapefile_path)\n",
    "    taxi_zones = taxi_zones.to_crs(4326)  # Reproject to lat/lon (WGS84)\n",
    "    taxi_zones['lon'] = taxi_zones.centroid.x  # Calculate longitude from centroid\n",
    "    taxi_zones['lat'] = taxi_zones.centroid.y  # Calculate latitude from centroid\n",
    "    return taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_coords_for_taxi_zone_id(zone_loc_id, loaded_taxi_zones):\n",
    "    zone = loaded_taxi_zones[loaded_taxi_zones['LocationID'] == zone_loc_id]\n",
    "    if not zone.empty:\n",
    "        return zone.iloc[0]['lat'], zone.iloc[0]['lon']\n",
    "    return None, None  # Return None if the location ID is invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d31728-9c65-47d8-b57e-6c63527d0475",
   "metadata": {},
   "source": [
    "Create a representative sample using Cochran's Sample Size Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(population, margin_of_error=0.05):\n",
    "    z = 1.96  # For 95% confidence\n",
    "    p = 0.5  # Assumed proportion of 50% (worst-case scenario)\n",
    "    q = 1 - p\n",
    "    e = margin_of_error\n",
    "    pop = population.shape[0]\n",
    "    # Cochran's sample size formula\n",
    "    sample_size = (z ** 2 * p * q) / (e ** 2)\n",
    "    # Adjust sample size for finite population\n",
    "    sample_size = sample_size / (1 + (sample_size - 1) / pop)\n",
    "    sampled_df = population.sample(n=math.ceil(sample_size), random_state=42)\n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82a613-9c23-46bc-b97c-451c14b0eb3e",
   "metadata": {},
   "source": [
    "Append latitude and longitude coordinates for pickup and drop-off locations to taxi_data DataFrame by mapping them from a preloaded taxi zones dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c6a78da-9c4a-401f-a3d2-3354bf28bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates_to_taxi_data(taxi_data, loaded_taxi_zones):\n",
    "    taxi_data[['PUlat', 'PUlon']] = taxi_data['PULocationID'].apply(\n",
    "        lambda x: pd.Series(lookup_coords_for_taxi_zone_id(x, loaded_taxi_zones))\n",
    "    )\n",
    "    taxi_data[['DOlat', 'DOlon']] = taxi_data['DOLocationID'].apply(\n",
    "        lambda x: pd.Series(lookup_coords_for_taxi_zone_id(x, loaded_taxi_zones))\n",
    "    )\n",
    "    taxi_data = taxi_data.drop(columns=['PULocationID', 'DOLocationID'])\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca3c1d5-6058-4bfc-9e49-c228c1e85036",
   "metadata": {},
   "source": [
    "1. Load Data: Reads a Parquet file specified by path into a pandas DataFrame using pd.read_parquet().\n",
    "\n",
    "2. Initial Filtering:\n",
    " - Removes trips with zero or negative distances (trip_distance > 0).\n",
    " - Excludes trips where the pickup and drop-off locations are the same (PULocationID != DOLocationID).\n",
    " - Ensures the PULocationID and DOLocationID values are within the valid range of 1–263 .\n",
    "\n",
    "3. Handle Missing Data: Drops rows with missing values in the trip_distance, PULocationID, or DOLocationID columns.\n",
    "\n",
    "4. Sampling: Calculates the required sample size using calculate_sample_size() and selects a random sample from the dataset.\n",
    "\n",
    "5. Add Geographic Coordinates: Enriches the dataset by adding latitude and longitude columns for both pickup and drop-off locations using the add_coordinates_to_taxi_data() function.\n",
    "\n",
    "6. Filter by Geographic Boundaries: Filters trips to ensure pickup and drop-off locations are within specific latitude and longitude ranges.\n",
    "\n",
    "7. Remove Unnecessary Columns: Drops columns that are not relevant for further analysis, such as: RatecodeID, store_and_fwd_flag, payment_type, Monetary columns: fare_amount, extra, tolls_amount, improvement_surcharge, congestion_surcharge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month(path, loaded_taxi_zones):\n",
    "    a = pd.read_parquet(path)\n",
    "    a = a[(a['trip_distance'] > 0) & (a['PULocationID'] != a['DOLocationID'])]\n",
    "    # Ensures the PULocationID and DOLocationID values are within the valid range of 1–263\n",
    "    a = a[(a['PULocationID'] >= 1) & (a['PULocationID'] <= 263)]\n",
    "    a = a[(a['DOLocationID'] >= 1) & (a['DOLocationID'] <= 263)]\n",
    "    # drop nan\n",
    "    a = a.dropna(subset=['trip_distance', 'PULocationID', 'DOLocationID'])  \n",
    "    # get sample\n",
    "    a = calculate_sample_size(a)\n",
    "    # Convert ID to lat lon\n",
    "    a = add_coordinates_to_taxi_data(a, loaded_taxi_zones)\n",
    "    # Filter by latitude\n",
    "    a = a[a['PUlat'].between(40.560445, 40.908524)] \n",
    "    a = a[a['DOlat'].between(40.560445, 40.908524)] \n",
    "    # Filter by longitude\n",
    "    a = a[a['PUlon'].between(-74.242330, -73.717047)] \n",
    "    a = a[a['DOlon'].between(-74.242330, -73.717047)]  \n",
    "    a = a.drop(['RatecodeID', 'store_and_fwd_flag', 'payment_type', \n",
    "            'fare_amount', 'extra', \n",
    "            'tolls_amount', 'improvement_surcharge', \n",
    "            'congestion_surcharge'], axis=1)\n",
    "    # more clean step\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4205321b-197d-46b7-8316-d697111f0821",
   "metadata": {},
   "source": [
    "* Cleaning each file individually.\n",
    "* Merging all the cleaned files into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(parquet_urls):\n",
    "    all_taxi_dataframes = []\n",
    "    loaded_taxi_zones = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "    for parquet_url in tqdm(parquet_urls):\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month(parquet_url, loaded_taxi_zones)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        all_taxi_dataframes.append(dataframe.sort_values(by='tpep_pickup_datetime', ascending=True))  \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes, ignore_index=True)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c982d4-cef6-4b3a-aac4-6df9f1be8d4a",
   "metadata": {},
   "source": [
    "Return a cleaned and combined dataset of taxi trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_data():\n",
    "    taxi_path.sort()\n",
    "    taxi_data = get_and_clean_taxi_data(taxi_path)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "876bd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 57/57 [00:28<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>PUlat</th>\n",
       "      <th>PUlon</th>\n",
       "      <th>DOlat</th>\n",
       "      <th>DOlon</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 00:56:39</td>\n",
       "      <td>2020-01-01 01:21:13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.712459</td>\n",
       "      <td>-73.998151</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 02:09:23</td>\n",
       "      <td>2020-01-01 02:24:08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.35</td>\n",
       "      <td>20.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:35:25</td>\n",
       "      <td>2020-01-01 03:06:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.86</td>\n",
       "      <td>35.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.761493</td>\n",
       "      <td>-73.919694</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 03:11:10</td>\n",
       "      <td>2020-01-01 03:23:52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.96</td>\n",
       "      <td>29.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.766238</td>\n",
       "      <td>-73.995135</td>\n",
       "      <td>40.841709</td>\n",
       "      <td>-73.941399</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 03:49:45</td>\n",
       "      <td>2020-01-01 03:59:46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.804334</td>\n",
       "      <td>-73.951292</td>\n",
       "      <td>40.818258</td>\n",
       "      <td>-73.940772</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2020-01-01 00:56:39   2020-01-01 01:21:13              2.0   \n",
       "1         1  2020-01-01 02:09:23   2020-01-01 02:24:08              3.0   \n",
       "2         2  2020-01-01 02:35:25   2020-01-01 03:06:56              1.0   \n",
       "3         2  2020-01-01 03:11:10   2020-01-01 03:23:52              6.0   \n",
       "4         1  2020-01-01 03:49:45   2020-01-01 03:59:46              2.0   \n",
       "\n",
       "   trip_distance  mta_tax  tip_amount  total_amount  airport_fee      PUlat  \\\n",
       "0           3.80      0.5        0.00         20.30          NaN  40.756729   \n",
       "1           3.30      0.5        3.35         20.15          NaN  40.736824   \n",
       "2           6.82      0.5        5.86         35.16          NaN  40.756729   \n",
       "3           6.91      0.5        4.96         29.76          NaN  40.766238   \n",
       "4           1.40      0.5        0.00          9.80          NaN  40.804334   \n",
       "\n",
       "       PUlon      DOlat      DOlon  Airport_fee  \n",
       "0 -73.965146  40.712459 -73.998151          NaN  \n",
       "1 -73.984052  40.775932 -73.946510          NaN  \n",
       "2 -73.965146  40.761493 -73.919694          NaN  \n",
       "3 -73.995135  40.841709 -73.941399          NaN  \n",
       "4 -73.951292  40.818258 -73.940772          NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37c1b3-2c89-4970-8e2d-5a6df595e0b2",
   "metadata": {},
   "source": [
    "Adjust columns' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1886536-077a-4ea1-81d9-383634f1220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'VendorID': 'vendor_id',\n",
    "    'tpep_pickup_datetime': 'pickup_time',\n",
    "    'tpep_dropoff_datetime': 'dropoff_time',\n",
    "    'passenger_count': 'passenger_count',\n",
    "    'trip_distance': 'trip_distance',\n",
    "    'mta_tax': 'tax',\n",
    "    'tip_amount': 'tip',\n",
    "    'total_amount': 'total_amount',\n",
    "    'airport_fee': 'airport_fee',\n",
    "    'PUlat':'pickup_lat',\n",
    "    'PUlon':'pickup_lon',\n",
    "    'DOlat':'dropoff_lat',\n",
    "    'DOlon':'dropoff_lon',\n",
    "    'Airport_fee':'fee'\n",
    "}\n",
    "\n",
    "taxi_data = taxi_data.rename(columns=new_column_names)\n",
    "taxi_data = taxi_data.drop(columns=['fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f775767-f1c0-44b8-aced-eb85beeeb988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>tax</th>\n",
       "      <th>tip</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 00:56:39</td>\n",
       "      <td>2020-01-01 01:21:13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.712459</td>\n",
       "      <td>-73.998151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 02:09:23</td>\n",
       "      <td>2020-01-01 02:24:08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.35</td>\n",
       "      <td>20.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 02:35:25</td>\n",
       "      <td>2020-01-01 03:06:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.86</td>\n",
       "      <td>35.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.761493</td>\n",
       "      <td>-73.919694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-01 03:11:10</td>\n",
       "      <td>2020-01-01 03:23:52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.96</td>\n",
       "      <td>29.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.766238</td>\n",
       "      <td>-73.995135</td>\n",
       "      <td>40.841709</td>\n",
       "      <td>-73.941399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01 03:49:45</td>\n",
       "      <td>2020-01-01 03:59:46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.804334</td>\n",
       "      <td>-73.951292</td>\n",
       "      <td>40.818258</td>\n",
       "      <td>-73.940772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id         pickup_time        dropoff_time  passenger_count  \\\n",
       "0          1 2020-01-01 00:56:39 2020-01-01 01:21:13              2.0   \n",
       "1          1 2020-01-01 02:09:23 2020-01-01 02:24:08              3.0   \n",
       "2          2 2020-01-01 02:35:25 2020-01-01 03:06:56              1.0   \n",
       "3          2 2020-01-01 03:11:10 2020-01-01 03:23:52              6.0   \n",
       "4          1 2020-01-01 03:49:45 2020-01-01 03:59:46              2.0   \n",
       "\n",
       "   trip_distance  tax   tip  total_amount  airport_fee  pickup_lat  \\\n",
       "0           3.80  0.5  0.00         20.30          NaN   40.756729   \n",
       "1           3.30  0.5  3.35         20.15          NaN   40.736824   \n",
       "2           6.82  0.5  5.86         35.16          NaN   40.756729   \n",
       "3           6.91  0.5  4.96         29.76          NaN   40.766238   \n",
       "4           1.40  0.5  0.00          9.80          NaN   40.804334   \n",
       "\n",
       "   pickup_lon  dropoff_lat  dropoff_lon  \n",
       "0  -73.965146    40.712459   -73.998151  \n",
       "1  -73.984052    40.775932   -73.946510  \n",
       "2  -73.965146    40.761493   -73.919694  \n",
       "3  -73.995135    40.841709   -73.941399  \n",
       "4  -73.951292    40.818258   -73.940772  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9da7089-3f6b-4f93-a22e-76bf554daca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21934 entries, 0 to 21933\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   vendor_id        21934 non-null  int64         \n",
      " 1   pickup_time      21934 non-null  datetime64[us]\n",
      " 2   dropoff_time     21934 non-null  datetime64[us]\n",
      " 3   passenger_count  20795 non-null  float64       \n",
      " 4   trip_distance    21934 non-null  float64       \n",
      " 5   tax              21934 non-null  float64       \n",
      " 6   tip              21934 non-null  float64       \n",
      " 7   total_amount     21934 non-null  float64       \n",
      " 8   airport_fee      8187 non-null   float64       \n",
      " 9   pickup_lat       21934 non-null  float64       \n",
      " 10  pickup_lon       21934 non-null  float64       \n",
      " 11  dropoff_lat      21934 non-null  float64       \n",
      " 12  dropoff_lon      21934 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(10), int64(1)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50c85e25-6416-4c16-b98c-09596cdc6865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>tax</th>\n",
       "      <th>tip</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934</td>\n",
       "      <td>21934</td>\n",
       "      <td>20795.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>8187.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "      <td>21934.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.718291</td>\n",
       "      <td>2022-05-17 09:16:22.064511</td>\n",
       "      <td>2022-05-17 09:33:11.525896</td>\n",
       "      <td>1.396778</td>\n",
       "      <td>4.616993</td>\n",
       "      <td>0.492523</td>\n",
       "      <td>2.738133</td>\n",
       "      <td>22.656455</td>\n",
       "      <td>0.083975</td>\n",
       "      <td>40.752857</td>\n",
       "      <td>-73.967122</td>\n",
       "      <td>40.755038</td>\n",
       "      <td>-73.970701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020-01-01 00:56:39</td>\n",
       "      <td>2020-01-01 01:21:13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-23.920000</td>\n",
       "      <td>-146.500000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.170887</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-03-09 23:50:52</td>\n",
       "      <td>2021-03-10 00:02:31.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2022-05-15 21:10:08.500000</td>\n",
       "      <td>2022-05-15 21:21:54.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>17.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2023-07-25 04:12:52.250000</td>\n",
       "      <td>2023-07-25 07:09:02.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>25.185000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.959635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2024-09-30 19:22:33</td>\n",
       "      <td>2024-09-30 19:41:06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>24137.690000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>187.780000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>40.897932</td>\n",
       "      <td>-73.735554</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.449842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976673</td>\n",
       "      <td>164.542840</td>\n",
       "      <td>0.079543</td>\n",
       "      <td>3.138831</td>\n",
       "      <td>17.752309</td>\n",
       "      <td>0.316574</td>\n",
       "      <td>0.032189</td>\n",
       "      <td>0.045494</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.036873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vendor_id                 pickup_time                dropoff_time  \\\n",
       "count  21934.000000                       21934                       21934   \n",
       "mean       1.718291  2022-05-17 09:16:22.064511  2022-05-17 09:33:11.525896   \n",
       "min        1.000000         2020-01-01 00:56:39         2020-01-01 01:21:13   \n",
       "25%        1.000000         2021-03-09 23:50:52  2021-03-10 00:02:31.250000   \n",
       "50%        2.000000  2022-05-15 21:10:08.500000  2022-05-15 21:21:54.500000   \n",
       "75%        2.000000  2023-07-25 04:12:52.250000  2023-07-25 07:09:02.500000   \n",
       "max        2.000000         2024-09-30 19:22:33         2024-09-30 19:41:06   \n",
       "std        0.449842                         NaN                         NaN   \n",
       "\n",
       "       passenger_count  trip_distance           tax           tip  \\\n",
       "count     20795.000000   21934.000000  21934.000000  21934.000000   \n",
       "mean          1.396778       4.616993      0.492523      2.738133   \n",
       "min           0.000000       0.010000     -0.500000    -23.920000   \n",
       "25%           1.000000       1.150000      0.500000      0.000000   \n",
       "50%           1.000000       1.870000      0.500000      2.200000   \n",
       "75%           1.000000       3.500000      0.500000      3.500000   \n",
       "max           6.000000   24137.690000      0.500000     50.000000   \n",
       "std           0.976673     164.542840      0.079543      3.138831   \n",
       "\n",
       "       total_amount  airport_fee    pickup_lat    pickup_lon   dropoff_lat  \\\n",
       "count  21934.000000  8187.000000  21934.000000  21934.000000  21934.000000   \n",
       "mean      22.656455     0.083975     40.752857    -73.967122     40.755038   \n",
       "min     -146.500000    -1.250000     40.576961    -74.170887     40.576961   \n",
       "25%       12.960000     0.000000     40.740337    -73.989845     40.740337   \n",
       "50%       17.160000     0.000000     40.756729    -73.977698     40.758028   \n",
       "75%       25.185000     0.000000     40.773633    -73.965146     40.775932   \n",
       "max      187.780000     1.250000     40.897932    -73.735554     40.899529   \n",
       "std       17.752309     0.316574      0.032189      0.045494      0.033799   \n",
       "\n",
       "        dropoff_lon  \n",
       "count  21934.000000  \n",
       "mean     -73.970701  \n",
       "min      -74.174000  \n",
       "25%      -73.989845  \n",
       "50%      -73.977698  \n",
       "75%      -73.959635  \n",
       "max      -73.726655  \n",
       "std        0.036873  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea169042-5c3f-485d-8dcd-fd1284cc7b1d",
   "metadata": {},
   "source": [
    "1. Load Data: Reads the Parquet file from the specified url into a pandas DataFrame.\n",
    "\n",
    "2. Filter by License: Retains only trips associated with hvfhs_license_num == 'HV0003' (representing Uber data).\n",
    "\n",
    "3. Initial Filtering: Excludes trips with non-positive trip distances.\n",
    " - Removes trips where the pickup (PULocationID) and drop-off (DOLocationID) locations are the same.\n",
    " - Retains only rows where PULocationID and DOLocationID are within the valid range of 1–263.\n",
    "\n",
    "4. Handle Missing Data: Drops rows with missing values in trip_distance, PULocationID, or DOLocationID.\n",
    "\n",
    "5. Sampling: Reduces the dataset size by calculating and selecting an appropriate sample using calculate_sample_size().\n",
    "\n",
    "6. Add Geographic Coordinates: Enriches the dataset by adding latitude and longitude columns for both pickup and drop-off locations using the add_coordinates_to_taxi_data() function.\n",
    "\n",
    "7. Filter by Geographic Boundaries: Ensures that the latitude and longitude of both pickup and drop-off locations fall within specified geographic boundaries.\n",
    "\n",
    "8. Drop Unnecessary Columns: Removes columns irrelevant for further analysis: Monetary columns: sales_tax, base_passenger_fare, driver_pay.\n",
    "Flags and fees: shared_request_flag, shared_match_flag, access_a_ride_flag, wav_request_flag, wav_match_flag, bcf, airport_fee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07574983-f41d-4cd6-8f70-489493089b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_month(url, loaded_taxi_zones):\n",
    "    # uber\n",
    "    a = pd.read_parquet(url)\n",
    "    a = a[(a['hvfhs_license_num'] == 'HV0003')]\n",
    "    a = a.rename(columns={'trip_miles': 'trip_distance'})\n",
    "    a = a[(a['trip_distance'] > 0) & (a['PULocationID'] != a['DOLocationID'])]\n",
    "    a = a[(a['PULocationID'] >= 1) & (a['PULocationID'] <= 263)]\n",
    "    a = a[(a['DOLocationID'] >= 1) & (a['DOLocationID'] <= 263)]\n",
    "    a = a.dropna(subset=['trip_distance', 'PULocationID', 'DOLocationID'])  \n",
    "    a = calculate_sample_size(a)\n",
    "    a = add_coordinates_to_taxi_data(a, loaded_taxi_zones)\n",
    "    # Filter by latitude\n",
    "    a = a[a['PUlat'].between(40.560445, 40.908524)] \n",
    "    a = a[a['DOlat'].between(40.560445, 40.908524)] \n",
    "    # Filter by longitude\n",
    "    a = a[a['PUlon'].between(-74.242330, -73.717047)] \n",
    "    a = a[a['DOlon'].between(-74.242330, -73.717047)]  \n",
    "    a = a.drop(['sales_tax', 'base_passenger_fare', 'driver_pay', \n",
    "            'shared_request_flag', 'shared_match_flag', \n",
    "            'access_a_ride_flag', 'wav_request_flag', \n",
    "            'wav_match_flag','bcf','airport_fee'], axis=1)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567f7e2-93f8-4245-9c1a-b3df4dcb53eb",
   "metadata": {},
   "source": [
    "Processes and consolidates Uber trip data from multiple Parquet files into a single cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b3d85ff-313c-41a2-9a46-261a9a2bb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_data(parquet_urls):\n",
    "    all_uber_dataframes = []\n",
    "    loaded_taxi_zones = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "    for parquet_url in tqdm(parquet_urls):\n",
    "        dataframe = get_and_clean_uber_month(parquet_url, loaded_taxi_zones)\n",
    "        all_uber_dataframes.append(dataframe.sort_values(by='pickup_datetime', ascending=True))  \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    uber_data = pd.concat(all_uber_dataframes, ignore_index=True)\n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    hvfhv_path.sort()\n",
    "    taxi_data = get_and_clean_uber_data(hvfhv_path)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 57/57 [05:25<00:00,  5.71s/it]\n"
     ]
    }
   ],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>tolls</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>tips</th>\n",
       "      <th>PUlat</th>\n",
       "      <th>PUlon</th>\n",
       "      <th>DOlat</th>\n",
       "      <th>DOlon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02872</td>\n",
       "      <td>B02872</td>\n",
       "      <td>2020-01-01 00:35:28</td>\n",
       "      <td>2020-01-01 00:40:04</td>\n",
       "      <td>2020-01-01 00:42:54</td>\n",
       "      <td>2020-01-01 00:58:30</td>\n",
       "      <td>2.01</td>\n",
       "      <td>936</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.658744</td>\n",
       "      <td>-73.947442</td>\n",
       "      <td>40.652365</td>\n",
       "      <td>-73.922251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02889</td>\n",
       "      <td>B02889</td>\n",
       "      <td>2020-01-01 04:20:12</td>\n",
       "      <td>2020-01-01 04:20:47</td>\n",
       "      <td>2020-01-01 04:25:07</td>\n",
       "      <td>2020-01-01 04:44:12</td>\n",
       "      <td>4.71</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.715370</td>\n",
       "      <td>-73.936793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02836</td>\n",
       "      <td>B02836</td>\n",
       "      <td>2020-01-01 04:45:28</td>\n",
       "      <td>2020-01-01 04:48:10</td>\n",
       "      <td>2020-01-01 04:49:22</td>\n",
       "      <td>2020-01-01 05:08:37</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "      <td>40.695338</td>\n",
       "      <td>-73.986086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02835</td>\n",
       "      <td>B02835</td>\n",
       "      <td>2020-01-01 06:15:30</td>\n",
       "      <td>2020-01-01 06:19:21</td>\n",
       "      <td>2020-01-01 06:20:19</td>\n",
       "      <td>2020-01-01 06:29:43</td>\n",
       "      <td>1.94</td>\n",
       "      <td>564</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.652365</td>\n",
       "      <td>-73.922251</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02883</td>\n",
       "      <td>B02883</td>\n",
       "      <td>2020-01-01 16:06:43</td>\n",
       "      <td>2020-01-01 16:11:01</td>\n",
       "      <td>2020-01-01 16:11:14</td>\n",
       "      <td>2020-01-01 16:47:16</td>\n",
       "      <td>17.51</td>\n",
       "      <td>2162</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.646985</td>\n",
       "      <td>-73.786533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0            HV0003               B02872               B02872   \n",
       "1            HV0003               B02889               B02889   \n",
       "2            HV0003               B02836               B02836   \n",
       "3            HV0003               B02835               B02835   \n",
       "4            HV0003               B02883               B02883   \n",
       "\n",
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2020-01-01 00:35:28 2020-01-01 00:40:04 2020-01-01 00:42:54   \n",
       "1 2020-01-01 04:20:12 2020-01-01 04:20:47 2020-01-01 04:25:07   \n",
       "2 2020-01-01 04:45:28 2020-01-01 04:48:10 2020-01-01 04:49:22   \n",
       "3 2020-01-01 06:15:30 2020-01-01 06:19:21 2020-01-01 06:20:19   \n",
       "4 2020-01-01 16:06:43 2020-01-01 16:11:01 2020-01-01 16:11:14   \n",
       "\n",
       "     dropoff_datetime  trip_distance  trip_time  tolls  congestion_surcharge  \\\n",
       "0 2020-01-01 00:58:30           2.01        936   0.00                  0.00   \n",
       "1 2020-01-01 04:44:12           4.71       1145   0.00                  2.75   \n",
       "2 2020-01-01 05:08:37           4.07       1155   0.00                  0.00   \n",
       "3 2020-01-01 06:29:43           1.94        564   0.00                  0.00   \n",
       "4 2020-01-01 16:47:16          17.51       2162   6.12                  2.75   \n",
       "\n",
       "   tips      PUlat      PUlon      DOlat      DOlon  \n",
       "0   0.0  40.658744 -73.947442  40.652365 -73.922251  \n",
       "1   0.0  40.718938 -73.990896  40.715370 -73.936793  \n",
       "2   0.0  40.674469 -73.939287  40.695338 -73.986086  \n",
       "3   0.0  40.652365 -73.922251  40.674469 -73.939287  \n",
       "4   0.0  40.758028 -73.977698  40.646985 -73.786533  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "422ca3b4-776b-458c-94d4-15607c2d4abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'hvfhs_license_num': 'license_number',\n",
    "    'dispatching_base_num': 'dispatch_base',\n",
    "    'originating_base_num': 'origin_base',\n",
    "    'request_datetime': 'request_time',\n",
    "    'on_scene_datetime': 'on_scene_time',\n",
    "    'pickup_datetime': 'pickup_time',\n",
    "    'dropoff_datetime': 'dropoff_time',\n",
    "    'trip_distance': 'trip_distance',\n",
    "    'trip_time': 'trip_duration',\n",
    "    'tolls': 'tolls_amount',\n",
    "    'congestion_surcharge': 'congestion_fee',\n",
    "    'tips': 'tips',\n",
    "    'PUlat': 'pickup_lat',\n",
    "    'PUlon': 'pickup_lon',\n",
    "    'DOlat': 'dropoff_lat',\n",
    "    'DOlon': 'dropoff_lon'\n",
    "}\n",
    "\n",
    "uber_data = uber_data.rename(columns=new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8900b53a-249e-4136-bcbe-517cd52c8a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>license_number</th>\n",
       "      <th>dispatch_base</th>\n",
       "      <th>origin_base</th>\n",
       "      <th>request_time</th>\n",
       "      <th>on_scene_time</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>congestion_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02872</td>\n",
       "      <td>B02872</td>\n",
       "      <td>2020-01-01 00:35:28</td>\n",
       "      <td>2020-01-01 00:40:04</td>\n",
       "      <td>2020-01-01 00:42:54</td>\n",
       "      <td>2020-01-01 00:58:30</td>\n",
       "      <td>2.01</td>\n",
       "      <td>936</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.658744</td>\n",
       "      <td>-73.947442</td>\n",
       "      <td>40.652365</td>\n",
       "      <td>-73.922251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02889</td>\n",
       "      <td>B02889</td>\n",
       "      <td>2020-01-01 04:20:12</td>\n",
       "      <td>2020-01-01 04:20:47</td>\n",
       "      <td>2020-01-01 04:25:07</td>\n",
       "      <td>2020-01-01 04:44:12</td>\n",
       "      <td>4.71</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.715370</td>\n",
       "      <td>-73.936793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02836</td>\n",
       "      <td>B02836</td>\n",
       "      <td>2020-01-01 04:45:28</td>\n",
       "      <td>2020-01-01 04:48:10</td>\n",
       "      <td>2020-01-01 04:49:22</td>\n",
       "      <td>2020-01-01 05:08:37</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "      <td>40.695338</td>\n",
       "      <td>-73.986086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02835</td>\n",
       "      <td>B02835</td>\n",
       "      <td>2020-01-01 06:15:30</td>\n",
       "      <td>2020-01-01 06:19:21</td>\n",
       "      <td>2020-01-01 06:20:19</td>\n",
       "      <td>2020-01-01 06:29:43</td>\n",
       "      <td>1.94</td>\n",
       "      <td>564</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.652365</td>\n",
       "      <td>-73.922251</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02883</td>\n",
       "      <td>B02883</td>\n",
       "      <td>2020-01-01 16:06:43</td>\n",
       "      <td>2020-01-01 16:11:01</td>\n",
       "      <td>2020-01-01 16:11:14</td>\n",
       "      <td>2020-01-01 16:47:16</td>\n",
       "      <td>17.51</td>\n",
       "      <td>2162</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.646985</td>\n",
       "      <td>-73.786533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  license_number dispatch_base origin_base        request_time  \\\n",
       "0         HV0003        B02872      B02872 2020-01-01 00:35:28   \n",
       "1         HV0003        B02889      B02889 2020-01-01 04:20:12   \n",
       "2         HV0003        B02836      B02836 2020-01-01 04:45:28   \n",
       "3         HV0003        B02835      B02835 2020-01-01 06:15:30   \n",
       "4         HV0003        B02883      B02883 2020-01-01 16:06:43   \n",
       "\n",
       "        on_scene_time         pickup_time        dropoff_time  trip_distance  \\\n",
       "0 2020-01-01 00:40:04 2020-01-01 00:42:54 2020-01-01 00:58:30           2.01   \n",
       "1 2020-01-01 04:20:47 2020-01-01 04:25:07 2020-01-01 04:44:12           4.71   \n",
       "2 2020-01-01 04:48:10 2020-01-01 04:49:22 2020-01-01 05:08:37           4.07   \n",
       "3 2020-01-01 06:19:21 2020-01-01 06:20:19 2020-01-01 06:29:43           1.94   \n",
       "4 2020-01-01 16:11:01 2020-01-01 16:11:14 2020-01-01 16:47:16          17.51   \n",
       "\n",
       "   trip_duration  tolls_amount  congestion_fee  tips  pickup_lat  pickup_lon  \\\n",
       "0            936          0.00            0.00   0.0   40.658744  -73.947442   \n",
       "1           1145          0.00            2.75   0.0   40.718938  -73.990896   \n",
       "2           1155          0.00            0.00   0.0   40.674469  -73.939287   \n",
       "3            564          0.00            0.00   0.0   40.652365  -73.922251   \n",
       "4           2162          6.12            2.75   0.0   40.758028  -73.977698   \n",
       "\n",
       "   dropoff_lat  dropoff_lon  \n",
       "0    40.652365   -73.922251  \n",
       "1    40.715370   -73.936793  \n",
       "2    40.695338   -73.986086  \n",
       "3    40.674469   -73.939287  \n",
       "4    40.646985   -73.786533  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74d783db-e527-4847-bf70-2d7428ea3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21851 entries, 0 to 21850\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   license_number  21851 non-null  object        \n",
      " 1   dispatch_base   21851 non-null  object        \n",
      " 2   origin_base     21846 non-null  object        \n",
      " 3   request_time    21851 non-null  datetime64[us]\n",
      " 4   on_scene_time   21851 non-null  datetime64[us]\n",
      " 5   pickup_time     21851 non-null  datetime64[us]\n",
      " 6   dropoff_time    21851 non-null  datetime64[us]\n",
      " 7   trip_distance   21851 non-null  float64       \n",
      " 8   trip_duration   21851 non-null  int64         \n",
      " 9   tolls_amount    21851 non-null  float64       \n",
      " 10  congestion_fee  21851 non-null  float64       \n",
      " 11  tips            21851 non-null  float64       \n",
      " 12  pickup_lat      21851 non-null  float64       \n",
      " 13  pickup_lon      21851 non-null  float64       \n",
      " 14  dropoff_lat     21851 non-null  float64       \n",
      " 15  dropoff_lon     21851 non-null  float64       \n",
      "dtypes: datetime64[us](4), float64(8), int64(1), object(3)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fddeb14-cd70-4e83-8f93-974642c3bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_time</th>\n",
       "      <th>on_scene_time</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>congestion_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21851</td>\n",
       "      <td>21851</td>\n",
       "      <td>21851</td>\n",
       "      <td>21851</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "      <td>21851.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-17 06:34:01.349320</td>\n",
       "      <td>2022-05-17 06:37:34.917898</td>\n",
       "      <td>2022-05-17 06:38:41.947554</td>\n",
       "      <td>2022-05-17 06:57:22.341860</td>\n",
       "      <td>4.651595</td>\n",
       "      <td>1120.405473</td>\n",
       "      <td>0.714933</td>\n",
       "      <td>1.106185</td>\n",
       "      <td>0.846985</td>\n",
       "      <td>40.739567</td>\n",
       "      <td>-73.936109</td>\n",
       "      <td>40.739079</td>\n",
       "      <td>-73.936559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:35:28</td>\n",
       "      <td>2020-01-01 00:40:04</td>\n",
       "      <td>2020-01-01 00:42:54</td>\n",
       "      <td>2020-01-01 00:58:30</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.170887</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-09 03:50:29.500000</td>\n",
       "      <td>2021-03-09 03:52:57</td>\n",
       "      <td>2021-03-09 03:54:20.500000</td>\n",
       "      <td>2021-03-09 04:07:55.500000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>614.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.694428</td>\n",
       "      <td>-73.985156</td>\n",
       "      <td>40.691831</td>\n",
       "      <td>-73.984196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-16 20:09:29</td>\n",
       "      <td>2022-05-16 20:11:49</td>\n",
       "      <td>2022-05-16 20:13:51</td>\n",
       "      <td>2022-05-16 20:47:52</td>\n",
       "      <td>3.060000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.739496</td>\n",
       "      <td>-73.949540</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.948891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-07-24 13:05:29</td>\n",
       "      <td>2023-07-24 13:06:21.500000</td>\n",
       "      <td>2023-07-24 13:08:02</td>\n",
       "      <td>2023-07-24 13:31:55.500000</td>\n",
       "      <td>5.920000</td>\n",
       "      <td>1419.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.775965</td>\n",
       "      <td>-73.900316</td>\n",
       "      <td>40.775965</td>\n",
       "      <td>-73.899735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-09-30 23:15:10</td>\n",
       "      <td>2024-09-30 23:15:59</td>\n",
       "      <td>2024-09-30 23:18:01</td>\n",
       "      <td>2024-09-30 23:37:29</td>\n",
       "      <td>37.470000</td>\n",
       "      <td>8173.000000</td>\n",
       "      <td>51.350000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>43.670000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.370277</td>\n",
       "      <td>729.895150</td>\n",
       "      <td>2.736384</td>\n",
       "      <td>1.343959</td>\n",
       "      <td>2.539146</td>\n",
       "      <td>0.067755</td>\n",
       "      <td>0.063597</td>\n",
       "      <td>0.068204</td>\n",
       "      <td>0.066896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     request_time               on_scene_time  \\\n",
       "count                       21851                       21851   \n",
       "mean   2022-05-17 06:34:01.349320  2022-05-17 06:37:34.917898   \n",
       "min           2020-01-01 00:35:28         2020-01-01 00:40:04   \n",
       "25%    2021-03-09 03:50:29.500000         2021-03-09 03:52:57   \n",
       "50%           2022-05-16 20:09:29         2022-05-16 20:11:49   \n",
       "75%           2023-07-24 13:05:29  2023-07-24 13:06:21.500000   \n",
       "max           2024-09-30 23:15:10         2024-09-30 23:15:59   \n",
       "std                           NaN                         NaN   \n",
       "\n",
       "                      pickup_time                dropoff_time  trip_distance  \\\n",
       "count                       21851                       21851   21851.000000   \n",
       "mean   2022-05-17 06:38:41.947554  2022-05-17 06:57:22.341860       4.651595   \n",
       "min           2020-01-01 00:42:54         2020-01-01 00:58:30       0.210000   \n",
       "25%    2021-03-09 03:54:20.500000  2021-03-09 04:07:55.500000       1.730000   \n",
       "50%           2022-05-16 20:13:51         2022-05-16 20:47:52       3.060000   \n",
       "75%           2023-07-24 13:08:02  2023-07-24 13:31:55.500000       5.920000   \n",
       "max           2024-09-30 23:18:01         2024-09-30 23:37:29      37.470000   \n",
       "std                           NaN                         NaN       4.370277   \n",
       "\n",
       "       trip_duration  tolls_amount  congestion_fee          tips  \\\n",
       "count   21851.000000  21851.000000    21851.000000  21851.000000   \n",
       "mean     1120.405473      0.714933        1.106185      0.846985   \n",
       "min        68.000000      0.000000        0.000000      0.000000   \n",
       "25%       614.500000      0.000000        0.000000      0.000000   \n",
       "50%       932.000000      0.000000        0.000000      0.000000   \n",
       "75%      1419.000000      0.000000        2.750000      0.000000   \n",
       "max      8173.000000     51.350000        2.750000     43.670000   \n",
       "std       729.895150      2.736384        1.343959      2.539146   \n",
       "\n",
       "         pickup_lat    pickup_lon   dropoff_lat   dropoff_lon  \n",
       "count  21851.000000  21851.000000  21851.000000  21851.000000  \n",
       "mean      40.739567    -73.936109     40.739079    -73.936559  \n",
       "min       40.561994    -74.170887     40.561994    -74.174000  \n",
       "25%       40.694428    -73.985156     40.691831    -73.984196  \n",
       "50%       40.739496    -73.949540     40.740337    -73.948891  \n",
       "75%       40.775965    -73.900316     40.775965    -73.899735  \n",
       "max       40.899529    -73.726655     40.899529    -73.726655  \n",
       "std        0.067755      0.063597      0.068204      0.066896  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_1)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "pd.read_sql(QUERY_1, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
